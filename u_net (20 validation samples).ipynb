{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "class TrainDataset(data.Dataset):\n",
    "    def __init__(self, root=''):\n",
    "        super(TrainDataset, self).__init__()\n",
    "        self.img_files = glob(os.path.join(root,'image','*.png'))\n",
    "        self.img_files.sort()\n",
    "        self.mask_files = []\n",
    "        for img_path in self.img_files:\n",
    "            basename = os.path.basename(img_path)\n",
    "            self.mask_files.append(os.path.join(root,'mask',basename[:-4]+'_mask.png'))\n",
    "        # get the path of these images  \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "            img_path = self.img_files[index]\n",
    "            mask_path = self.mask_files[index]\n",
    "            data = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "            label = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
    "            return torch.from_numpy(data).float(), torch.from_numpy(label).float(), img_path\n",
    "            #change it from numpy to tesnor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "        # how many train images\n",
    "\n",
    "class TestDataset(data.Dataset):\n",
    "    def __init__(self, root=''):\n",
    "        super(TestDataset, self).__init__()\n",
    "        self.img_files = glob(os.path.join(root,'image','*.png'))\n",
    "        self.img_files.sort()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "            img_path = self.img_files[index]\n",
    "            data = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "            return torch.from_numpy(data).float(), img_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "            \n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "#         diffY = x2.size()[2] - x1.size()[2]\n",
    "#         diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "#         x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "#                         diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        \n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 512)\n",
    "        \n",
    "        self.up1 = Up(1024, 256)\n",
    "        self.up2 = Up(512, 128)\n",
    "        self.up3 = Up(256, 64)\n",
    "        self.up4 = Up(128, 64)\n",
    "        \n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "\n",
    "        \n",
    "        x2 = self.down1(x1)\n",
    "\n",
    "        x3 = self.down2(x2)\n",
    "\n",
    "        x4 = self.down3(x3)\n",
    "\n",
    "        x5 = self.down4(x4)\n",
    "\n",
    "        \n",
    "        x = self.up1(x5, x4)\n",
    "\n",
    "        x = self.up2(x, x3)\n",
    "\n",
    "            \n",
    "        x = self.up3(x, x2)\n",
    "\n",
    "        \n",
    "        x = self.up4(x, x1)\n",
    "\n",
    "        logits = self.outc(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "model = UNet(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "Loss = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.175, nesterov=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MattH\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "1516.0692520141602\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "data_path = './data/train'\n",
    "path = './data/unet_sgd_0.175N.pt'\n",
    "num_workers = 0\n",
    "batch_size = 4\n",
    "train_set = TrainDataset(data_path)\n",
    "training_data_loader = DataLoader(dataset=train_set, num_workers=num_workers, batch_size=batch_size, shuffle=True)\n",
    "num_epochs = 20\n",
    "# Fetch images and labels. \n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    model.train()\n",
    "    for iteration, sample in enumerate(training_data_loader):\n",
    "        img, mask, name = sample\n",
    "\n",
    "        img1 = img.unsqueeze(1)\n",
    "\n",
    "        # Write your FORWARD below\n",
    "        # Note: Input image to your model and ouput the predicted mask and Your predicted mask should have 4 channels\n",
    "    \n",
    "\n",
    " \n",
    "        y_predict = model.forward(img1)\n",
    "        \n",
    "\n",
    "#         mask = torch.tensor(mask, dtype = torch.long)\n",
    "        mask = mask.type(torch.long)\n",
    "\n",
    "        loss = Loss(y_predict, mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Then write your BACKWARD & OPTIMIZE below\n",
    "        # Note: Compute Loss and Optimize\n",
    "    \n",
    "       \n",
    "        \n",
    "    torch.save(model.state_dict(), path)\n",
    "finish = time.time()\n",
    "train_time = finish - start\n",
    "print(train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "path = './data/unet_sgd_0.175N.pt'\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 2\n",
    "\n",
    "val_path = './data/val/'\n",
    "val_set = TrainDataset(val_path)\n",
    "val_data_loader = DataLoader(dataset=val_set, num_workers=num_workers,batch_size=batch_size, shuffle=False)\n",
    "\n",
    "i= 101\n",
    "\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()\n",
    "for iteration, sample in enumerate(val_data_loader):\n",
    "    \n",
    "    img, mask, name = sample\n",
    "    img2 = img.unsqueeze(1)\n",
    "\n",
    "    x = model.forward(img2)\n",
    "    \n",
    "    mask1 = x[0]\n",
    "    mask2 = x[1]\n",
    "\n",
    "    \n",
    "    mask1 = torch.argmax(mask1.squeeze(), dim=0)\n",
    "    mask2 = torch.argmax(mask2.squeeze(), dim=0)\n",
    "\n",
    "    mask1 = mask1.detach().numpy()\n",
    "    mask2 = mask2.detach().numpy()\n",
    "    cv2.imwrite('./data/val/mask2/cmr{}_mask.png'.format(i), mask1)\n",
    "    i += 1\n",
    "    cv2.imwrite('./data/val/mask2/cmr{}_mask.png'.format(i), mask2)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this block you are expected to write code to load saved model and deploy it to all data in test set to \n",
    "# produce segmentation masks in png images valued 0,1,2,3, which will be used for the submission to Kaggle.\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "path = './data/unet_sgd_0.175.pt'\n",
    "\n",
    "test_path = './data/test'\n",
    "num_workers = 0\n",
    "batch_size = 2\n",
    "\n",
    "test_set = TestDataset(test_path)\n",
    "test_data_loader = DataLoader(dataset=test_set, num_workers=num_workers, batch_size = batch_size, shuffle=False)\n",
    "i= 121\n",
    "\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()\n",
    "for sample, name in test_data_loader:\n",
    "\n",
    "    img = sample.unsqueeze(1)\n",
    "\n",
    "    x = model.forward(img)\n",
    "    \n",
    "    mask1 = x[0]\n",
    "    mask2 = x[1]\n",
    "    \n",
    "    mask1 = torch.argmax(mask1.squeeze(), dim=0)\n",
    "    mask2 = torch.argmax(mask2.squeeze(), dim=0)\n",
    "\n",
    "\n",
    "    mask1 = mask1.detach().numpy()\n",
    "    mask2 = mask2.detach().numpy()\n",
    "\n",
    "    cv2.imwrite('./data/test/mask/cmr{}_mask.png'.format(i), mask1)\n",
    "    i += 1\n",
    "    cv2.imwrite('./data/test/mask/cmr{}_mask.png'.format(i), mask2)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_dice(mask1, mask2, label_class=1):\n",
    "    \"\"\"\n",
    "    Dice score of a specified class between two volumes of label masks.\n",
    "    (classes are encoded but by label class number not one-hot )\n",
    "    Note: stacks of 2D slices are considered volumes.\n",
    "\n",
    "    Args:\n",
    "        mask1: N label masks, numpy array shaped (H, W, N)\n",
    "        mask2: N label masks, numpy array shaped (H, W, N)\n",
    "        label_class: the class over which to calculate dice scores\n",
    "\n",
    "    Returns:\n",
    "        volume_dice\n",
    "    \"\"\"\n",
    "    mask1_pos = (mask1 == label_class).astype(np.float32)\n",
    "    mask2_pos = (mask2 == label_class).astype(np.float32)\n",
    "    dice = 2 * np.sum(mask1_pos * mask2_pos) / (np.sum(mask1_pos) + np.sum(mask2_pos))\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7738146544147702\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_dir = './data/val'\n",
    "mask1 =cv2.imread(os.path.join(data_dir,'mask','cmr103_mask.png'), cv2.IMREAD_UNCHANGED)\n",
    "mask2 = cv2.imread(os.path.join(data_dir,'mask2','cmr103_mask.png'), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "label_class = 2\n",
    "x = categorical_dice(mask1, mask2, label_class)\n",
    "mask11 =cv2.imread(os.path.join(data_dir,'mask','cmr101_mask.png'), cv2.IMREAD_UNCHANGED)\n",
    "mask12 = cv2.imread(os.path.join(data_dir,'mask2','cmr101_mask.png'), cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "mask21 =cv2.imread(os.path.join(data_dir,'mask','cmr102_mask.png'), cv2.IMREAD_UNCHANGED)\n",
    "mask22 = cv2.imread(os.path.join(data_dir,'mask2','cmr102_mask.png'), cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "mask31 =cv2.imread(os.path.join(data_dir,'mask','cmr103_mask.png'), cv2.IMREAD_UNCHANGED)\n",
    "mask32 = cv2.imread(os.path.join(data_dir,'mask2','cmr103_mask.png'), cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "mask41 =cv2.imread(os.path.join(data_dir,'mask','cmr104_mask.png'), cv2.IMREAD_UNCHANGED)\n",
    "mask42 = cv2.imread(os.path.join(data_dir,'mask2','cmr104_mask.png'), cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "mask51 =cv2.imread(os.path.join(data_dir,'mask','cmr105_mask.png'), cv2.IMREAD_UNCHANGED)\n",
    "mask52 = cv2.imread(os.path.join(data_dir,'mask2','cmr105_mask.png'), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "\n",
    "true_mask =np.array([mask11, mask21, mask31, mask41, mask51])\n",
    "predict_mask = np.array([mask12, mask22, mask32, mask42, mask52])\n",
    "\n",
    "                        \n",
    "\n",
    "# label_class = 2\n",
    "\n",
    "#y = categorical_dice(mask1, mask2, 0)\n",
    "#print(y)\n",
    "sum5 = 0\n",
    "for i in range(5):\n",
    "\n",
    "    summary = 0\n",
    "    labe_class = 0\n",
    "    for j in range(3):\n",
    "        x = categorical_dice(true_mask[i], predict_mask[i], labe_class)\n",
    "        summary +=x\n",
    "        labe_class +=1\n",
    "    average = summary/3\n",
    "    sum5 +=average\n",
    "    #print(average)\n",
    "\n",
    "print(sum5/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPDATED USING 20 VALIDATION SAMPLES INSTEAD OF 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7295323859322067\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/val'\n",
    "#true_mask = np.array([])\n",
    "#predict_mask = np.array([])\n",
    "true_mask = []\n",
    "predict_mask = []\n",
    "for i in range(101,121):\n",
    "    true_mask.append(cv2.imread(os.path.join(data_dir,'mask','cmr{}_mask.png'.format(i)), cv2.IMREAD_UNCHANGED))\n",
    "    predict_mask.append(cv2.imread(os.path.join(data_dir,'mask2','cmr{}_mask.png'.format(i)), cv2.IMREAD_UNCHANGED))\n",
    "    \n",
    "#print(true_mask)\n",
    "\n",
    "sum20 = 0\n",
    "for i in range(20):\n",
    "    summary = 0\n",
    "    labe_class = 0\n",
    "    for j in range(3):\n",
    "        x = categorical_dice(true_mask[i], predict_mask[i], labe_class)\n",
    "        summary +=x\n",
    "        labe_class +=1\n",
    "    average = summary/3\n",
    "    sum20 +=average\n",
    "    #print(average)\n",
    "\n",
    "print(sum20/20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def rle_encoding(x):\n",
    "    '''\n",
    "    *** Credit to https://www.kaggle.com/rakhlin/fast-run-length-encoding-python ***\n",
    "    x: numpy array of shape (height, width), 1 - mask, 0 - background\n",
    "    Returns run length as list\n",
    "    '''\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b > prev + 1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "\n",
    "def submission_converter(mask_directory, path_to_save):\n",
    "    writer = open(os.path.join(path_to_save, \"submission.csv\"), 'w')\n",
    "    writer.write('id,encoding\\n')\n",
    "\n",
    "    files = os.listdir(mask_directory)\n",
    "\n",
    "\n",
    "\n",
    "    for file in files:\n",
    "        name = file[:-4]\n",
    "        mask = cv2.imread(os.path.join(mask_directory, file), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        \n",
    "        mask1 = (mask == 1)\n",
    "        mask2 = (mask == 2)\n",
    "        mask3 = (mask == 3)\n",
    "\n",
    "\n",
    "        encoded_mask1 = rle_encoding(mask1)\n",
    "        encoded_mask1 = ' '.join(str(e) for e in encoded_mask1)\n",
    "        encoded_mask2 = rle_encoding(mask2)\n",
    "        encoded_mask2 = ' '.join(str(e) for e in encoded_mask2)\n",
    "        encoded_mask3 = rle_encoding(mask3)\n",
    "        encoded_mask3 = ' '.join(str(e) for e in encoded_mask3)\n",
    "\n",
    "        writer.write(name + '1,' + encoded_mask1 + \"\\n\")\n",
    "        writer.write(name + '2,' + encoded_mask2 + \"\\n\")\n",
    "        writer.write(name + '3,' + encoded_mask3 + \"\\n\")\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_converter(\"C:/Users/MattH/Desktop/CW2 - Neural Computation/CW2/data/test/mask\", \"C:/Users/MattH/Desktop/CW2 - Neural Computation/CW2/data/test/submission_directory\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
